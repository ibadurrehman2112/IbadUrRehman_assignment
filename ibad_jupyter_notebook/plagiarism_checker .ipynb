{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1191037521.py, line 22)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_193215/1191037521.py\"\u001b[0;36m, line \u001b[0;32m22\u001b[0m\n\u001b[0;31m    // Get list of all files in dir, recursively.\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Plagiarism Checker\n",
    "----------------------------------------\n",
    "\"\"\"\n",
    "import click\n",
    "from .matcher import Text, ExtendedMatch, Matcher\n",
    "import os\n",
    "import glob\n",
    "import csv\n",
    "import logging\n",
    "import itertools\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "def getFiles(path): \n",
    "    \"\"\" \n",
    "    Determines whether a path is a file or directory. \n",
    "    If it's a directory, it gets a list of all the text files \n",
    "    in that directory, recursively. If not, it gets the file. \n",
    "    \"\"\"\n",
    "    if os.path.isfile(path): \n",
    "        return [path]\n",
    "    elif os.path.isdir(path): \n",
    "        // Get list of all files in dir, recursively. \n",
    "        return glob.glob(path + \"/**/*.txt\", recursive=True)\n",
    "    else: \n",
    "        raise click.ClickException(\"The path %s doesn't appear to be a file or directory\" % path) \n",
    "def checkLog(logfile, textpair): \n",
    "    \"\"\" \n",
    "    Checks the log file to make sure we haven't already done a particular analysis. \n",
    "    Returns True if the pair is in the log already. \n",
    "    \"\"\"\n",
    "    pairs = []\n",
    "    logging.debug('Looking in the log for textpair:' % textpair)\n",
    "    if not os.path.isfile(logfile): \n",
    "        logging.debug('No log file found.')\n",
    "        return None\n",
    "    with open(logfile, newline='') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            pairs.append([row[0], row[1]])\n",
    "    // logging.debug('Pairs already in log: %s' % pairs)\n",
    "    return textpair in pairs\n",
    "def createLog(logfile, columnLabels): \n",
    "    \"\"\" \n",
    "    Creates a log file and sets up headers so that it can be easily read \n",
    "    as a CSV later. \n",
    "    \"\"\"\n",
    "    header = ','.join(columnLabels) + '\\n'\n",
    "    with open(logfile, 'w') as f: \n",
    "        f.write(header) \n",
    "        f.close\n",
    "@click.command()\n",
    "@click.argument('text1')\n",
    "@click.argument('text2') \n",
    "@click.option('-t', '--threshold', type=int, default=3, \\\n",
    "        help='The shortest length of match to include in the list of initial matches.')\n",
    "@click.option('-c', '--cutoff', type=int, default=5, \\\n",
    "        help='The shortest length of match to include in the final list of extended matches.')\n",
    "@click.option('-n', '--ngrams', type=int, default=3, \\\n",
    "        help='The ngram n-value to match against.')\n",
    "@click.option('-l', '--logfile', default='log.txt', help='The name of the log file to write to.'\n",
    "@click.option('--stops', is_flag=True, help='Include stopwords in matching.', default=False)\n",
    "@click.option('--verbose', is_flag=True, help='Enable verbose mode, giving more information.')\n",
    "def cli(text1, text2, threshold, cutoff, ngrams, logfile, verbose, stops):\n",
    "    \"\"\" This program finds similar text in two text files. \"\"\"\n",
    "    //Determine whether the given path is a file or directory. \n",
    "    texts1 = getFiles(text1)\n",
    "    texts2 = getFiles(text2) \n",
    "    if verbose: \n",
    "        logging.basicConfig(level=logging.DEBUG)\n",
    "    if stops: \n",
    "        logging.debug('Including stopwords in tokenizing.') \n",
    "    logging.debug('Comparing this/these text(s): %s' % str(texts1))\n",
    "    logging.debug('with this/these text(s): %s' % str(texts2))\n",
    "    pairs = list(itertools.product(texts1, texts2))\n",
    "    numPairs = len(pairs) \n",
    "    logging.debug('Comparing %s pairs.' % numPairs)\n",
    "    // logging.debug('List of pairs to compare: %s' % pairs)\n",
    "    logging.debug('Loading files into memory.')\n",
    "    texts = {}\n",
    "    prevTextObjs = {}\n",
    "    for filename in texts1+texts2: \n",
    "        with open(filename, errors=\"ignore\") as f: \n",
    "            text = f.read() \n",
    "        if filename not in texts: \n",
    "            texts[filename] = text\n",
    "    logging.debug('Loading complete.')\n",
    "    for index, pair in enumerate(pairs): \n",
    "        timeStart = os.times().elapsed\n",
    "        logging.debug('Now comparing pair %s of %s.' % (index+1, numPairs))\n",
    "        logging.debug('Comparing %s with %s.' % (pair[0], pair[1]))\n",
    "        // Make sure we haven't already done this pair. \n",
    "        inLog = checkLog(logfile, [pair[0], pair[1]])\n",
    "        if inLog is None: \n",
    "            // This means that there isn't a log file. Let's set one up.\n",
    "            // Set up columns and their labels. \n",
    "            columnLabels = ['Text A', 'Text B', 'Threshold', 'Cutoff', 'N-Grams', 'Num Matches', 'Text A Length', 'Text B Length', 'Locations in A', 'Locations in B']\n",
    "            logging.debug('No log file found. Setting one up.')\n",
    "            createLog(logfile, columnLabels)\n",
    "        if inLog: \n",
    "            logging.debug('This pair is already in the log. Skipping.')\n",
    "            continue\n",
    "        logging.debug('Processing texts.')\n",
    "        filenameA, filenameB = pair[0], pair[1]\n",
    "        textA, textB = texts[filenameA], texts[filenameB]\n",
    "        // Put this in a dictionary so we don't have to process a file twice.\n",
    "        for filename in [filenameA, filenameB]: \n",
    "            if filename not in prevTextObjs: \n",
    "                logging.debug('Processing text: %s' % filename)\n",
    "                prevTextObjs[filename] = Text(texts[filename], filename)\n",
    "        // Just more convenient naming. \n",
    "        textObjA = prevTextObjs[filenameA]\n",
    "        textObjB = prevTextObjs[filenameB]\n",
    "        // Reset the table of previous text objects, so we don't overload memory. \n",
    "        // This means we'll only remember the previous two texts. \n",
    "        prevTextObjs = \n",
    "        // Do the matching. \n",
    "        myMatch = Matcher(textObjA, textObjB, threshold=threshold, cutoff=cutoff, ngramSize=ngrams, removeStopwords=stops)\n",
    "        myMatch.match()\n",
    "        timeEnd = os.times().elapsed\n",
    "        timeElapsed = timeEnd-timeStart\n",
    "        logging.debug('Matching completed in %s seconds.' % timeElapsed)\n",
    "        // Write to the log, but only if a match is found.\n",
    "        if myMatch.numMatches > 0: \n",
    "            logItems = [pair[0], pair[1], threshold, cutoff, ngrams, myMatch.numMatches, myMatch.textA.length, myMatch.textB.length, str(myMatch.locationsA), str(myMatch.locationsB)]\n",
    "            logging.debug('Logging items: %s' % str(logItems))\n",
    "            line = ','.join(['\"%s\"' % item for item in logItems]) + '\\n'\n",
    "            f = open(logfile, 'a')\n",
    "            f.write(line)\n",
    "            f.close()\n",
    "if __name__ == '__main__':\n",
    "    cli()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.8.0-cp39-cp39-manylinux2010_x86_64.whl (497.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 497.6 MB 6.5 kB/s eta 0:00:01    |█                               | 14.9 MB 95 kB/s eta 1:24:32     |█████▊                          | 88.2 MB 36 kB/s eta 3:08:33\n",
      "\u001b[?25hCollecting tf-estimator-nightly==2.8.0.dev2021122109\n",
      "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
      "\u001b[K     |████████████████████████████████| 462 kB 58 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.9.2 in /home/ibadhep/anaconda3/lib/python3.9/site-packages (from tensorflow) (3.19.4)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting flatbuffers>=1.12\n",
      "  Downloading flatbuffers-2.0-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/ibadhep/anaconda3/lib/python3.9/site-packages (from tensorflow) (3.3.0)\n",
      "Collecting keras<2.9,>=2.8.0rc0\n",
      "  Downloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4 MB 133 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.24.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 140 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting libclang>=9.0.1\n",
      "  Downloading libclang-13.0.0-py2.py3-none-manylinux1_x86_64.whl (14.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.5 MB 108 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 52 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in /home/ibadhep/anaconda3/lib/python3.9/site-packages (from tensorflow) (3.10.0.2)\n",
      "Requirement already satisfied: setuptools in /home/ibadhep/anaconda3/lib/python3.9/site-packages (from tensorflow) (58.0.4)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/ibadhep/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.1.0)\n",
      "Collecting tensorboard<2.9,>=2.8\n",
      "  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.8 MB 83 kB/s eta 0:00:013\n",
      "\u001b[?25hCollecting keras-preprocessing>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 78 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wrapt>=1.11.0 in /home/ibadhep/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/ibadhep/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.44.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.3 MB 63 kB/s eta 0:00:014\n",
      "\u001b[?25hRequirement already satisfied: absl-py>=0.4.0 in /home/ibadhep/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/ibadhep/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.20.3)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 58 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gast>=0.2.1\n",
      "  Downloading gast-0.5.3-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/ibadhep/anaconda3/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/ibadhep/anaconda3/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.26.0)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "\u001b[K     |████████████████████████████████| 781 kB 207 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: werkzeug>=0.11.15 in /home/ibadhep/anaconda3/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.0.2)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.6.2-py2.py3-none-any.whl (156 kB)\n",
      "\u001b[K     |████████████████████████████████| 156 kB 119 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.9 MB 62 kB/s eta 0:00:017\n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.6-py3-none-any.whl (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 35 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.8-py3-none-any.whl (39 kB)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/ibadhep/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (5.0.0)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[K     |████████████████████████████████| 155 kB 34 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/ibadhep/anaconda3/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ibadhep/anaconda3/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.6.0)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "\u001b[K     |████████████████████████████████| 77 kB 41 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: idna<4,>=2.5 in /home/ibadhep/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ibadhep/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ibadhep/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ibadhep/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "\u001b[K     |████████████████████████████████| 151 kB 41 kB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pyasn1, rsa, pyasn1-modules, oauthlib, requests-oauthlib, google-auth, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, tf-estimator-nightly, tensorflow-io-gcs-filesystem, tensorboard, opt-einsum, libclang, keras-preprocessing, keras, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "Successfully installed astunparse-1.6.3 flatbuffers-2.0 gast-0.5.3 google-auth-2.6.2 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.44.0 keras-2.8.0 keras-preprocessing-1.1.2 libclang-13.0.0 markdown-3.3.6 oauthlib-3.2.0 opt-einsum-3.3.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 rsa-4.8 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.8.0 tensorflow-io-gcs-filesystem-0.24.0 tf-estimator-nightly-2.8.0.dev2021122109\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: turtle in /home/ibadhep/anaconda3/lib/python3.9/site-packages (0.0.1)\n",
      "Requirement already satisfied: PyYAML>=3.08 in /home/ibadhep/anaconda3/lib/python3.9/site-packages (from turtle) (6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install turtle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /home/ibadhep/anaconda3/lib/python3.9/site-packages (2.8.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement pickle (from versions: none)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for pickle\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /home/ibadhep/anaconda3/lib/python3.9/site-packages (3.6.5)\n",
      "Requirement already satisfied: click in /home/ibadhep/anaconda3/lib/python3.9/site-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: joblib in /home/ibadhep/anaconda3/lib/python3.9/site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/ibadhep/anaconda3/lib/python3.9/site-packages (from nltk) (2021.8.3)\n",
      "Requirement already satisfied: tqdm in /home/ibadhep/anaconda3/lib/python3.9/site-packages (from nltk) (4.62.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5e96b45ffd47e93248c606a67b27fda686db23833db56219cd282bf80879b1f1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
