{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\sarma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\sarma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\sarma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sarma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\sarma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "import spacy\n",
    "\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize, regexp_tokenize\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models.tfidfmodel import TfidfModel\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('words')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Let', 's', 'write', 'RegEx']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_string = \"Let's write RegEx!\"\n",
    "\n",
    "re.findall(r\"\\w+\", my_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**New String**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_a = \"Let's write RegEx!  Won't that be fun?  I sure think so.  Can you find 4 sentences?  Or perhaps, all 19 words?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split by ending sentence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Let's write RegEx\",\n",
       " \"  Won't that be fun\",\n",
       " '  I sure think so',\n",
       " '  Can you find 4 sentences',\n",
       " '  Or perhaps, all 19 words',\n",
       " '']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_ending = r\"[.?!]\"\n",
    "re.split(sentence_ending, string_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Find Capitalize Words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Let', 'RegEx', 'Won', 'Can', 'Or']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "capitalize = r\"[A-Z]\\w+\"\n",
    "re.findall(capitalize, string_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Find Spaces**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Let's\",\n",
       " 'write',\n",
       " 'RegEx!',\n",
       " \"Won't\",\n",
       " 'that',\n",
       " 'be',\n",
       " 'fun?',\n",
       " 'I',\n",
       " 'sure',\n",
       " 'think',\n",
       " 'so.',\n",
       " 'Can',\n",
       " 'you',\n",
       " 'find',\n",
       " '4',\n",
       " 'sentences?',\n",
       " 'Or',\n",
       " 'perhaps,',\n",
       " 'all',\n",
       " '19',\n",
       " 'words?']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spaces = r\"\\s+\"\n",
    "re.split(spaces, string_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Find Digits**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4', '19']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits = r\"\\d+\"\n",
    "re.findall(digits, string_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi', 'there', '!']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(\"Hi there!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Search for the first occurrence of \"coconuts\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cocunut = \"It's not a question of where he grips it!  It's a simple question of weight ratios!  A five ounce bird could not carry a one pound coconuts.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131 139\n"
     ]
    }
   ],
   "source": [
    "match = re.search(\"coconuts\", cocunut)\n",
    "\n",
    "# Print the start and end indexes of match\n",
    "print(match.start(), match.end())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regex Groups**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['He', 'has', '11', 'cats']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_b = \"He has 11 cats.\"\n",
    "match_dw = r\"\\d+|\\w+\"\n",
    "\n",
    "re.findall(match_dw, string_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 35), match='match lowercase spaces nums like 12'>\n"
     ]
    }
   ],
   "source": [
    "# Character Range with \"re.match\"\n",
    "my_str = \"match lowercase spaces nums like 12, but no commas\"\n",
    "exp = r\"[a-z0-9 ]+\"\n",
    "\n",
    "print(re.match(exp, my_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Choosing a tokenizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SOLDIER',\n",
       " '#1',\n",
       " 'Found',\n",
       " 'them',\n",
       " '?',\n",
       " 'In',\n",
       " 'Mercea',\n",
       " '?',\n",
       " 'The',\n",
       " 'coconut',\n",
       " 's',\n",
       " 'tropical',\n",
       " '!']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_string = \"SOLDIER #1: Found them? In Mercea? The coconut's tropical!\"\n",
    "\n",
    "exp_r = r\"(\\w+|#\\d|\\?|!)\"\n",
    "\n",
    "regexp_tokenize(my_string, exp_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extracting Hashtags from tweets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#nlp', '#python']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_1 = \"his is the best #nlp exercise ive found online! #python\"\n",
    "pattern1 = r\"#\\w+\"\n",
    "\n",
    "regexp_tokenize(tweet_1, pattern1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extracting Hashtags and Mentions from tweets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@datacamp', '#nlp', '#python']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_2 = \"Thanks @datacamp :) #nlp #python\"\n",
    "pattern2 = r\"[@|#]\\w+\"\n",
    "\n",
    "regexp_tokenize(tweet_2, pattern2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Charting word length with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1296x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "words = word_tokenize(\"This is a pretty cool tool!\")\n",
    "\n",
    "word_length = [len(w) for w in words]\n",
    "\n",
    "plt.figure(figsize = (18, 7))\n",
    "plt.hist(word_length)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_c = \"The cat is in the box. The cat likes the box. The box is over the cat.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'The': 3,\n",
       "         'cat': 3,\n",
       "         'is': 2,\n",
       "         'in': 1,\n",
       "         'the': 3,\n",
       "         'box': 3,\n",
       "         '.': 3,\n",
       "         'likes': 1,\n",
       "         'over': 1})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(word_tokenize(string_c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Common**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 3), ('cat', 3)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(word_tokenize(string_c)).most_common(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'The': 2, 'cat': 2, 'is': 1, 'in': 1, 'the': 1, 'box': 2, '.': 2})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_2 = \"The cat is in the box. The cat box.\"\n",
    "\n",
    "Counter(word_tokenize(string_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 2), ('cat', 2)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(word_tokenize(string_2)).most_common(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Counter with bag-of-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = \"A software bug is an error, flaw, failure or fault (technology)|fault in a computer program or software system|system that causes it to produce an incorrect or unexpected result, or to behave in unintended ways. Most bugs arise from mistakes and errors made in either a program's source code or its software architecture|design, or in components and operating systems used by such programs. A few are caused by compilers producing incorrect code. A program that contains a large number of bugs, and/or bugs that seriously interfere with its functionality, is said to be buggy (defective).\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 6), (',', 6), ('or', 6)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize the article\n",
    "tokens = word_tokenize(f)\n",
    "\n",
    "# Convert the tokens into lowercase\n",
    "lower_tokens = [t.lower() for t in tokens]\n",
    "\n",
    "# Create a Counter with the lowercase tokens\n",
    "bow_simple = Counter(lower_tokens)\n",
    "bow_simple.most_common(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The cat is in the box. The cat likes the box. The box is over the cat.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cat', 3), ('box', 3)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = [w for w in word_tokenize(text.lower()) if w.isalpha()] \n",
    "\n",
    "no_stops = [t for t in tokens if t not in stopwords.words(\"english\")]\n",
    "\n",
    "Counter(no_stops).most_common(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cat', 3), ('box', 3), ('like', 1)]\n"
     ]
    }
   ],
   "source": [
    "# Retain alphabetic words: alpha_only\n",
    "alpha_only = [t for t in word_tokenize(text.lower()) if t.isalpha()]\n",
    "\n",
    "# Remove all stop words: no_stops\n",
    "no_stops = [t for t in alpha_only if t not in stopwords.words(\"english\")]\n",
    "\n",
    "# Instantiate the WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Lemmatize all tokens into a new list: lemmatized\n",
    "lemmatized = [wordnet_lemmatizer.lemmatize(t) for t in no_stops]\n",
    "\n",
    "# Create the bag-of-words: bow\n",
    "bow = Counter(lemmatized)\n",
    "\n",
    "# Print the 10 most common tokens\n",
    "print(bow.most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = \"software bugs, or errors, are so prevalent and so detrimental that they cost the US economy an estimated $59&nbsp;billion annually, or about 0.6 percent of the gross domestic product. Government researchers, companies, and cyber security experts are the people who typically discover software flaws. The report calls for reforming computer crime and copyright laws.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'s': 0, 'o': 1, 'f': 2, 't': 3, 'w': 4, 'a': 5, 'r': 6, 'e': 7, 'b': 8, 'u': 9, 'g': 10, ',': 11, 'p': 12, 'v': 13, 'l': 14, 'n': 15, 'd': 16, 'i': 17, 'm': 18, 'h': 19, 'y': 20, 'c': 21, '$': 22, '5': 23, '9': 24, '&': 25, ';': 26, '0': 27, '.': 28, '6': 29, 'x': 30}\n"
     ]
    }
   ],
   "source": [
    "tokenize_words = [word_tokenize(w.lower()) for w in g]\n",
    "\n",
    "dictionary = Dictionary(tokenize_words)\n",
    "\n",
    "print(dictionary.token2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Gensim Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1)], [(1, 1)], [(2, 1)], [(3, 1)], [(4, 1)]]\n"
     ]
    }
   ],
   "source": [
    "corpus = [dictionary.doc2bow(doc) for doc in tokenize_words]\n",
    "print(corpus[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tf-idf with Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1.0)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfModel(corpus)\n",
    "tfidf[corpus[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"In New York, I like to ride thr Metro to visit MOMA and some restaurants rated well by Ruth Reichl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('In', 'IN'),\n",
       " ('New', 'NNP'),\n",
       " ('York', 'NNP'),\n",
       " (',', ','),\n",
       " ('I', 'PRP'),\n",
       " ('like', 'VBP'),\n",
       " ('to', 'TO'),\n",
       " ('ride', 'VB'),\n",
       " ('thr', 'RB'),\n",
       " ('Metro', 'NNP'),\n",
       " ('to', 'TO'),\n",
       " ('visit', 'VB'),\n",
       " ('MOMA', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('some', 'DT'),\n",
       " ('restaurants', 'NNS'),\n",
       " ('rated', 'VBN'),\n",
       " ('well', 'RB'),\n",
       " ('by', 'IN'),\n",
       " ('Ruth', 'NNP'),\n",
       " ('Reichl', 'NNP')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_sent = word_tokenize(sentence)\n",
    "tagged_sent = nltk.pos_tag(tokenized_sent)\n",
    "tagged_sent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building word count vectors with scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0        8476                       You Can Smell Hillary’s Fear   \n",
       "1       10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "\n",
       "                                                text label  \n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"fake_or_real_news.csv\")\n",
    "df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature\n",
    "X = df[\"text\"]\n",
    "\n",
    "# Target\n",
    "y = df[\"label\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a CountVectorizer object: count_vectorizer\n",
    "count_vectorizer = CountVectorizer(stop_words = \"english\", max_df = 0.7)\n",
    "\n",
    "\n",
    "# Transform the training data using only the 'text' column values: count_train \n",
    "count_train = count_vectorizer.fit_transform(X_train.values)\n",
    "\n",
    "\n",
    "# Transform the test data using only the 'text' column values: count_test \n",
    "count_test = count_vectorizer.transform(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00', '000', '0000', '000000031', '00000031']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the first 10 features of the count_vectorizer\n",
    "count_vectorizer.get_feature_names()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 33931)\t2\n",
      "  (0, 53309)\t1\n",
      "  (0, 16113)\t2\n",
      "  (0, 52709)\t25\n",
      "  (0, 11329)\t1\n",
      "  (0, 37778)\t1\n",
      "  (0, 21725)\t3\n",
      "  (0, 17236)\t2\n",
      "  (0, 40087)\t4\n",
      "  (0, 13860)\t7\n",
      "  (0, 18793)\t2\n",
      "  (0, 30857)\t1\n",
      "  (0, 20752)\t1\n",
      "  (0, 51857)\t3\n",
      "  (0, 43080)\t1\n",
      "  (0, 36360)\t1\n",
      "  (0, 33823)\t1\n",
      "  (0, 51390)\t3\n",
      "  (0, 25850)\t1\n",
      "  (0, 17289)\t1\n",
      "  (0, 16047)\t2\n",
      "  (0, 36100)\t1\n",
      "  (0, 42008)\t2\n",
      "  (0, 30837)\t1\n",
      "  (0, 14246)\t1\n",
      "  :\t:\n",
      "  (4, 56525)\t1\n",
      "  (4, 52368)\t1\n",
      "  (4, 42763)\t1\n",
      "  (4, 49498)\t1\n",
      "  (4, 36093)\t1\n",
      "  (4, 49897)\t1\n",
      "  (4, 5926)\t1\n",
      "  (4, 24526)\t1\n",
      "  (4, 43585)\t1\n",
      "  (4, 39960)\t1\n",
      "  (4, 22659)\t1\n",
      "  (4, 11205)\t1\n",
      "  (4, 23019)\t1\n",
      "  (4, 42886)\t1\n",
      "  (4, 25548)\t1\n",
      "  (4, 4482)\t1\n",
      "  (4, 19255)\t1\n",
      "  (4, 25468)\t1\n",
      "  (4, 40797)\t1\n",
      "  (4, 7778)\t1\n",
      "  (4, 13250)\t1\n",
      "  (4, 29092)\t1\n",
      "  (4, 50864)\t1\n",
      "  (4, 40437)\t1\n",
      "  (4, 9774)\t1\n"
     ]
    }
   ],
   "source": [
    "print(count_train[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TfidfVectorizer for text classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00', '000', '0000', '000000031', '00000031']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize a TfidfVectorizer object: tfidf_vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words = \"english\",\n",
    "                                   max_df = 0.7)\n",
    "\n",
    "# Transform the training data: tfidf_train \n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train.values)\n",
    "\n",
    "# Transform the test data: tfidf_test\n",
    "tfidf_test = tfidf_vectorizer.transform(X_test.values)\n",
    "\n",
    "# Print the first 10 features\n",
    "tfidf_vectorizer.get_feature_names()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.03791267 0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_train.A[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting the vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_df = pd.DataFrame(count_train.A,\n",
    "                        columns = count_vectorizer.get_feature_names())\n",
    "\n",
    "# Create the TfidfVectorizer DataFrame: tfidf_df\n",
    "tfidf_df = pd.DataFrame(tfidf_train.A,\n",
    "                        columns = tfidf_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0000</th>\n",
       "      <th>000000031</th>\n",
       "      <th>00000031</th>\n",
       "      <th>0001</th>\n",
       "      <th>0002</th>\n",
       "      <th>000billion</th>\n",
       "      <th>000ft</th>\n",
       "      <th>000km</th>\n",
       "      <th>...</th>\n",
       "      <th>שתי</th>\n",
       "      <th>תאמצנה</th>\n",
       "      <th>תוצאה</th>\n",
       "      <th>תחל</th>\n",
       "      <th>תיירות</th>\n",
       "      <th>תנותק</th>\n",
       "      <th>תעודת</th>\n",
       "      <th>תתרכז</th>\n",
       "      <th>القادمون</th>\n",
       "      <th>عربي</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 57841 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  0000  000000031  00000031  0001  0002  000billion  000ft  000km  \\\n",
       "0   0    0     0          0         0     0     0           0      0      0   \n",
       "1   0    0     0          0         0     0     0           0      0      0   \n",
       "2   0    0     0          0         0     0     0           0      0      0   \n",
       "3   0    4     0          0         0     0     0           0      0      0   \n",
       "4   0    0     0          0         0     0     0           0      0      0   \n",
       "\n",
       "   ...  שתי  תאמצנה  תוצאה  תחל  תיירות  תנותק  תעודת  תתרכז  القادمون  عربي  \n",
       "0  ...    0       0      0    0       0      0      0      0         0     0  \n",
       "1  ...    0       0      0    0       0      0      0      0         0     0  \n",
       "2  ...    0       0      0    0       0      0      0      0         0     0  \n",
       "3  ...    0       0      0    0       0      0      0      0         0     0  \n",
       "4  ...    0       0      0    0       0      0      0      0         0     0  \n",
       "\n",
       "[5 rows x 57841 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0000</th>\n",
       "      <th>000000031</th>\n",
       "      <th>00000031</th>\n",
       "      <th>0001</th>\n",
       "      <th>0002</th>\n",
       "      <th>000billion</th>\n",
       "      <th>000ft</th>\n",
       "      <th>000km</th>\n",
       "      <th>...</th>\n",
       "      <th>שתי</th>\n",
       "      <th>תאמצנה</th>\n",
       "      <th>תוצאה</th>\n",
       "      <th>תחל</th>\n",
       "      <th>תיירות</th>\n",
       "      <th>תנותק</th>\n",
       "      <th>תעודת</th>\n",
       "      <th>תתרכז</th>\n",
       "      <th>القادمون</th>\n",
       "      <th>عربي</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.037913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 57841 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    00       000  0000  000000031  00000031  0001  0002  000billion  000ft  \\\n",
       "0  0.0  0.000000   0.0        0.0       0.0   0.0   0.0         0.0    0.0   \n",
       "1  0.0  0.000000   0.0        0.0       0.0   0.0   0.0         0.0    0.0   \n",
       "2  0.0  0.000000   0.0        0.0       0.0   0.0   0.0         0.0    0.0   \n",
       "3  0.0  0.037913   0.0        0.0       0.0   0.0   0.0         0.0    0.0   \n",
       "4  0.0  0.000000   0.0        0.0       0.0   0.0   0.0         0.0    0.0   \n",
       "\n",
       "   000km  ...  שתי  תאמצנה  תוצאה  תחל  תיירות  תנותק  תעודת  תתרכז  القادمون  \\\n",
       "0    0.0  ...  0.0     0.0    0.0  0.0     0.0    0.0    0.0    0.0       0.0   \n",
       "1    0.0  ...  0.0     0.0    0.0  0.0     0.0    0.0    0.0    0.0       0.0   \n",
       "2    0.0  ...  0.0     0.0    0.0  0.0     0.0    0.0    0.0    0.0       0.0   \n",
       "3    0.0  ...  0.0     0.0    0.0  0.0     0.0    0.0    0.0    0.0       0.0   \n",
       "4    0.0  ...  0.0     0.0    0.0  0.0     0.0    0.0    0.0    0.0       0.0   \n",
       "\n",
       "   عربي  \n",
       "0   0.0  \n",
       "1   0.0  \n",
       "2   0.0  \n",
       "3   0.0  \n",
       "4   0.0  \n",
       "\n",
       "[5 rows x 57841 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_df[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes with Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1357</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2080</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2718</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4886</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Actual Predicted\n",
       "1357   FAKE      FAKE\n",
       "2080   FAKE      FAKE\n",
       "2718   FAKE      FAKE\n",
       "812    FAKE      REAL\n",
       "4886   FAKE      FAKE"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_classifier = MultinomialNB()\n",
    "\n",
    "nb_classifier.fit(count_train, y_train)\n",
    "\n",
    "pred = nb_classifier.predict(count_test)\n",
    "\n",
    "pd.DataFrame({\"Actual\": y_test, \"Predicted\": pred})[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8842714360862703"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[824 144]\n",
      " [ 76 857]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.92      0.85      0.88       968\n",
      "        REAL       0.86      0.92      0.89       933\n",
      "\n",
      "    accuracy                           0.88      1901\n",
      "   macro avg       0.89      0.88      0.88      1901\n",
      "weighted avg       0.89      0.88      0.88      1901\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and testing the \"fake news\" model with TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1357</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2080</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2718</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4886</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Actual Predicted\n",
       "1357   FAKE      FAKE\n",
       "2080   FAKE      FAKE\n",
       "2718   FAKE      FAKE\n",
       "812    FAKE      REAL\n",
       "4886   FAKE      FAKE"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Multinomial Naive Bayes classifier:\n",
    "nb_classifier = MultinomialNB()\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "nb_classifier.fit(tfidf_train, y_train)\n",
    "\n",
    "# Create the predicted tags\n",
    "pred = nb_classifier.predict(tfidf_test)\n",
    "\n",
    "pd.DataFrame({\"Actual\": y_test, \"Predicted\": pred})[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[646 322]\n",
      " [ 19 914]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.97      0.67      0.79       968\n",
      "        REAL       0.74      0.98      0.84       933\n",
      "\n",
      "    accuracy                           0.82      1901\n",
      "   macro avg       0.86      0.82      0.82      1901\n",
      "weighted avg       0.86      0.82      0.82      1901\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alpha</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.888480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.886902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.881115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.873225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.867964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.862704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.851131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.842714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.833246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.827985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Alpha     Score\n",
       "0    0.0  0.888480\n",
       "1    0.1  0.886902\n",
       "2    0.2  0.881115\n",
       "3    0.3  0.873225\n",
       "4    0.4  0.867964\n",
       "5    0.5  0.862704\n",
       "6    0.6  0.851131\n",
       "7    0.7  0.842714\n",
       "8    0.8  0.833246\n",
       "9    0.9  0.827985"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas = np.arange(0, 1, 0.1)\n",
    "model_score = []\n",
    "\n",
    "for a in alphas:\n",
    "    nb_classifier = MultinomialNB(alpha = a)\n",
    "    \n",
    "    nb_classifier.fit(tfidf_train, y_train)\n",
    "    \n",
    "    pred = nb_classifier.predict(tfidf_test)\n",
    "    \n",
    "    score = accuracy_score(y_test, pred)\n",
    "    \n",
    "    model_score.append(score)\n",
    "\n",
    "performance = pd.DataFrame({\"Alpha\": alphas,\n",
    "                            \"Score\": model_score})\n",
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alpha</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.88848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Alpha    Score\n",
       "0    0.0  0.88848"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_performance = performance[performance[\"Score\"] == performance[\"Score\"].max()]\n",
    "best_performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
